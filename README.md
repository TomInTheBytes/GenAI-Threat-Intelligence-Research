# Generative AI Threat Intelligence Research
This repository explores proof-of-concepts to integrate generative AI with threat intelligence. It is heavily inspired by the excellent [research](https://github.com/OTRF/GenAI-Security-Adventures) of Roberto Rodriguez ([@Cyb3rWard0g](https://github.com/Cyb3rWard0g)). It follows a similar structure with small alterations. It contains various Jupyter Notebooks that explore the different topics. Every notebook is documented and has various improvement ideas. 

## Threat Actor RAG
Retrieval Augmented Generation (RAG) is a method to retrieve context relevant for a chatbot prompt from a vector database. This way you can build a knowledge base and not be dependant on the LLMs context coverage and timeliness. You also have influence on what information the chatbot should work with and can prevent hallucinations. For more information see [this](https://blog.openthreatresearch.com/demystifying-generative-ai-a-security-researchers-notes/) great summary.

@Cyb3rWard0g already experimented with using MITRE's threat actor database as knowledge for a RAG. This database contains very structured and consistent documents. I was curious to see how other, less controlled threat actor information sources would perform. I decided to do a simple scrape of the [ETDA Threat Actor Encyclopedia](https://apt.etda.or.th/cgi-bin/aptgroups.cgi). This database contains over 450 threat actors and provides various hyperlinks to reports about operations and information about these threat actors. See "threat-actor-knowledge-builder.ipynb" and "threat-actor-QA.ipynb" for the experiment.

## Report Summarizer
The scraped reports vary in quality, length, and consistency. By summarizing them through an LLM we can iron out some of these issues. The summaries can also provide additional input for multi vector retrievers. This notebook describes how to loop over the reports and create summaries for reports where we can. It leverages OpenAI's API and deals with token limits. 

## Threat Actor Assessment
As an organization you want to prioritize your resources through threat intelligence. By assessing threat actors for their threat level to your organization you can look at their TTPs to learn and prepare for. However, threat actor assessment can take a lot of effort through manual work, especially when kept up to date. It is also difficult to be consistent on the analysis through time and different analysts. Generative AI could support this process by assessing reports through some model. By leveraging the [threat box model](https://klrgrz.medium.com/quantifying-threat-actors-with-threat-box-e6b641109b11) this notebook experiments with assessing threat actors through LLMs. 
